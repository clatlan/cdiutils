{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step BCDI analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Preprocessing](#preprocessing)\n",
    "    1. [Loading the data](#loading)\n",
    "    2. [Cropping the data](#cropping)\n",
    "    3. [Cleaning the data](#cleaning)\n",
    "3. [Phasing](#phasing)\n",
    "    1. [Initialisation](#initialisation)\n",
    "    2. [Running the phase retrieval](#running)\n",
    "    3. [Phasing result analysis](#phasing_result_analysis)\n",
    "4. [Orthogonalisation of the reconstructed data](#orthogonalisation)\n",
    "    1. [Define the geometry associated to the beamline](#geometry)\n",
    "    2. [Convention conversion](#convention)\n",
    "5. [Extracting quantitative structural properties](#properties)\n",
    "6. [Plotting](#plotting)\n",
    "7. [Saving](#saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "This notebook provides a step-by-step guide for users who intend to analyse their BCDI data. Another notebook is available, but requires knowledge of various ***cdiutils*** parameters. To further automate the data processing procedure, scripts can be used to process data faster.\n",
    "\n",
    "In this notebook, some code blocks are commented out. These correspond to optional plots/prints that you can check out for sanity verification.\n",
    "\n",
    "**Notes:**\n",
    "* In the following sections, some utility functions are used to display data when plotting requires more than one or two subplots. These functions do not perform any complex operations; they are just convenient ways to plot the data and simplify the code. If you want to check how the functions behave:\n",
    "    * For the function parameters: use ```function_name?```\n",
    "    * For the function source code: use ```function_name??```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import librairies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cdiutils\n",
    "\n",
    "# update the matplotlib parameters \n",
    "cdiutils.plot.update_plot_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing <a name=\"preprocessing\"></a>\n",
    "#### Loading the data <a name=\"loading\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data layering system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = \"\"  # the path to the /RAW_DATA dir of the experiment\n",
    "# Ex: path = \"/data/visitor/<experiment_name>/id01/<date>/RAW_DATA/\"\n",
    "!tree -L 1 {experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"\"  # Required\n",
    "experiment_file_path = f\"{experiment_path}/{experiment_name}_id01.h5\"\n",
    "print(f\"Experiment file path: {experiment_file_path}\")\n",
    "\n",
    "bliss_sample_name = \"\"  # Required\n",
    "bliss_dataset_name = \"\"  # Required\n",
    "scan = None  # Required\n",
    "\n",
    "sample_name = f\"{bliss_sample_name}_{bliss_dataset_name}\"\n",
    "\n",
    "\n",
    "loader = cdiutils.io.ID01Loader(\n",
    "    experiment_file_path=experiment_file_path,\n",
    "    sample_name=sample_name,\n",
    ")\n",
    "data = loader.load_detector_data(scan)\n",
    "\n",
    "print(f\"Shape of the detector data is: {data.shape}\")\n",
    "plt.figure(layout=\"tight\")\n",
    "plt.imshow(data[data.shape[0]//2], norm=LogNorm()); plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the detector data with an interactive slider plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdiutils.plot.Plotter(data, plot=\"2D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping the Data <a name=\"cropping\"></a>\n",
    "Find the Bragg Peak position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape[0] represents the number of frames in the rocking curve\n",
    "output_shape = (data.shape[0], 150, 150)\n",
    "\n",
    "# Crop the data according to specified methods. 'methods' can be a list\n",
    "# of strings such as \"com\" or \"max\", or it can be a tuple specifying the\n",
    "# reference detector pixel. The list can be as long as needed. Note that\n",
    "# if there are hot pixels, \"max\" or \"com\" might not work effectively.\n",
    "(\n",
    "    cropped_data,  # the output cropped data\n",
    "    det_ref,  # the detector reference voxel in the full detector frame\n",
    "    cropped_det_ref,  # the detector reference voxel in the cropped detector frame\n",
    "    roi  # the region of interest (ROI) used to crop the data\n",
    ") = cdiutils.utils.CroppingHandler.chain_centring(\n",
    "    data,\n",
    "    methods=[\"max\", \"com\"],  # the list of methods used sequentially\n",
    "    output_shape=output_shape,  # the output shape you want to work with\n",
    "    verbose=True  # whether to print logs during the reference voxel search\n",
    ")\n",
    "\n",
    "# Plot the cropped detector data\n",
    "loader.plot_detector_data(cropped_data, f\"Scan #{scan}\", equal_limits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data  <a name=\"cleaning\"></a>\n",
    "\n",
    "In this section, we will clean the data to improve its quality for analysis.\n",
    "\n",
    "* Hot pixels can be removed using a median filter-based function (`cdiutils.utils.hot_pixel_filter`).\n",
    "* Hot pixels can also be removed manually. For this, you can enable interactive plotting with `%matplotlib ipympl` and switch back to `%matplotlib inline` afterwards.\n",
    "* Use a flat field to improve data quality.\n",
    "* Remove background if fluorescence is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a flat field for the detector (at the correct energy), load and apply it.\n",
    "# flat_field_path = \"\"\n",
    "\n",
    "# with np.load(flat_field_path) as file:\n",
    "#     flat_field = file[\"arr_0\"][\n",
    "#         cdiutils.utils.CroppingHandler.roi_list_to_slices(roi[2:])\n",
    "#     ]\n",
    "# cleaned_data = cropped_data * flat_field\n",
    "\n",
    "# Remove hot pixels using a median filter-based function\n",
    "# cleaned_data = cropped_data\n",
    "cleaned_data, hot_pixel_mask = cdiutils.utils.hot_pixel_filter(cropped_data)\n",
    "\n",
    "# If you intend to remove background noise (e.g., fluorescence), set the\n",
    "# background level\n",
    "background_level = 4\n",
    "cleaned_data = np.where(\n",
    "    cleaned_data - background_level > 0,\n",
    "    cleaned_data - background_level, 0\n",
    ")\n",
    "\n",
    "# Plot the cleaned detector data\n",
    "loader.plot_detector_data(cleaned_data, f\"Scan #{scan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the mask with the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cdiutils.io.Loader.get_mask(\n",
    "    detector_name= ,  # Required,\n",
    "    channel=cleaned_data.shape[0],  # or data.shape[0] depending on the cropping\n",
    "    roi=roi\n",
    ")\n",
    "# mask *= hot_pixel_mask\n",
    "cdiutils.plot.plot_volume_slices(\n",
    "    mask, title=f\"Mask, scan #{scan}\", norm=Normalize()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phasing <a name=\"phasing\"></a>\n",
    "\n",
    "This part requires PyNX package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisation <a name=\"initialisation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally load a support from a former analysis\n",
    "# good_run_path = (\n",
    "#     f\"results/{sample_name}/S{scan}/pynx_phasing/.cxi\"\n",
    "# )\n",
    "# with cdiutils.io.CXIFile(run_path) as file:\n",
    "#     good_support = file[\"entry_1/image_1/support\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initiliase the PyNXPhaser. It is wrapper to embed and initialise PyNX\n",
    "# quickly. iobs (observed intensity) and mask are required. The\n",
    "# parameters (params) are optional, since most of them have a default\n",
    "# value.\n",
    "phaser = cdiutils.process.PyNXPhaser(\n",
    "    iobs=cleaned_data,\n",
    "    mask=mask,\n",
    "    params={\n",
    "        \"support_update\": 20,\n",
    "        \"support_threshold\": \"0.15, 0.40\",\n",
    "        \"show_cdi\": 0,\n",
    "        \"update_border_n\": None,\n",
    "        \"post_expand\": \"-1,1\",\n",
    "        \"rebin\": \"1, 1, 1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Initialise the CDI object. Support, or former cdi objects can be\n",
    "# provided.\n",
    "phaser.init_cdi(\n",
    "    # support=good_support,  # if you want to start from a known support\n",
    ")\n",
    "\n",
    "# Plot the first guess.\n",
    "phaser.plot_cdi(phaser.cdi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the phase retrieval  <a name=\"running\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the recipe you'd like to run.\n",
    "recipe = \"HIO**400, RAAR**500, ER**200\"\n",
    "phaser.run_multiple_instances(run_nb=5, recipe=recipe)\n",
    "\n",
    "# The genetic phasing requires smaller recipes.\n",
    "# recipe = \"HIO**50, RAAR**60, ER**40\"\n",
    "# phaser.genetic_phasing(\n",
    "#     run_nb=5, genetic_pass_nb=10,\n",
    "#     recipe=recipe, selection_method=\"mean_to_max\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the final results. This is just a first taste, you will be able to check out the reconstructions into more details right after. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, cdi in enumerate(phaser.cdi_list):\n",
    "    phaser.plot_cdi(cdi, title=f\"Run {i+1:04d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is if you want to select a specific good run and start the phasing again from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_run = 3\n",
    "\n",
    "# good_support = phaser.cdi_list[good_run -1].get_support(shift=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phasing results analysis <a name=\"phasing_result_analysis\"></a>\n",
    "The `cdiutils.process.PhasingResultAnalyser` class provides utility methods for analysing phase retrieval results.\n",
    "\n",
    "The method `cdiutils.process.PhasingResultAnalyser.analyse_phasing_results` sorts the results based on the provided `sorting_criterion`, which can be:\n",
    "\n",
    "* ```mean_to_max```: The difference between the mean of the Gaussian fitting of the amplitude histogram and the maximum value of the amplitude. A smaller difference indicates more homogeneous amplitude in the reconstruction.\n",
    "* the ```sharpness```: The sum of the amplitude within the support raised to the power of 4. For reconstructions with similar support, lower values indicate greater amplitude homogeneity.\n",
    "* ```std```: The standard deviation of the amplitude.\n",
    "* ```llk```: The log-likelihood of the reconstruction.\n",
    "* ```llkf```: The free log-likelihood of the reconstruction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = cdiutils.process.PhasingResultAnalyser(cdi_results=phaser.cdi_list)\n",
    "\n",
    "analyser.analyse_phasing_results(\n",
    "    sorting_criterion = \"mean_to_max\"\n",
    "    # plot_phasing_results=False,  # Defaults to True\n",
    "    # plot_phase=True,  # Defaults to False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the Best Candidates and Run Mode Decomposition\n",
    "\n",
    "In this cell, you have two options for selecting reconstructions:\n",
    "- Manually select the ```best_runs```: Create a list of integers corresponding to the run digit numbers based on your visual analysis of the previous outputs.\n",
    "- Automatically select the `nb_of_best_sorted_runs` (an integer) best runs using the `sorting_criterion` from the previous cell.\n",
    "\n",
    "After selecting the runs, a mode decomposition is performed to obtain the 'principal mode' of the chosen runs. This process is somewhat similar to Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser.select_best_candidates(\n",
    "    # best_runs=[2, 5]\n",
    "    nb_of_best_sorted_runs=3,\n",
    ")\n",
    "print(\n",
    "    f\"The best candidates selected are: {analyser.best_candidates}.\"\n",
    ")\n",
    "modes, mode_weight = analyser.mode_decomposition()\n",
    "\n",
    "mode = modes[0]  # Select the first mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Amplitude Distribution\n",
    "In this section, we check the amplitude distribution using the `cdiutils.utils.find_isosurface` function. Here's how it works:\n",
    "\n",
    "- The function estimates an isosurface based on the analysis of the amplitude histogram.\n",
    "\n",
    "- Assuming the right part of the histogram follows a Gaussian distribution, the isosurface is defined as $\\mu - 3\\sigma$, where $\\mu$ and $\\sigma$ represent the mean and standard deviation of the Gaussian density estimate.\n",
    "\n",
    "- Keep in mind that the computation may not be perfectly stable, but the resulting plot can guide you toward a relevant isosurface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isosurface, _ = cdiutils.utils.find_isosurface(np.abs(mode), plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Support Array and Calculate Oversampling Ratio\n",
    "\n",
    "In this part of the code, we perform the following steps:\n",
    "\n",
    "1. Define a `support` array that corresponds to the morphology of the object.\n",
    "2. Calculate the oversampling ratio in each direction.\n",
    "3. This oversampling information can be useful for re-phasing the data using the `rebin` parameter in PyNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isosurface = 0.45\n",
    "support = cdiutils.utils.make_support(np.abs(mode), isosurface=isosurface)\n",
    "\n",
    "ratios = cdiutils.utils.get_oversampling_ratios(support)\n",
    "print(\n",
    "    \"[INFO] The oversampling ratios in each direction are \"\n",
    "    + \", \".join(\n",
    "        [f\"axis{i}: {ratios[i]:.1f}\" for i in range(len(ratios))]\n",
    "    )\n",
    "    + \".\\nIf low-strain crystal, you can set PyNX 'rebin' parameter to \"\n",
    "            \"(\" + \", \".join([f\"{r//2}\" for r in ratios]) + \")\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the amplitude and phase of our final object (generated using our best reconstructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2, 3, layout=\"tight\", figsize=(6, 4))\n",
    "\n",
    "slices = cdiutils.utils.get_centred_slices(mode.shape)\n",
    "for i in range(3):\n",
    "    amp_img = axes[0, i].imshow(np.abs(mode)[slices[i]])\n",
    "    phase_img = axes[1, i].imshow(\n",
    "        np.angle(mode)[slices[i]], cmap=\"cet_CET_C9s_r\"\n",
    "    )\n",
    "\n",
    "    for ax in (axes[0, i], axes[1, i]):\n",
    "        cdiutils.plot.add_colorbar(ax, ax.images[0])\n",
    "        limits = cdiutils.plot.x_y_lim_from_support(support[slices[i]])\n",
    "        ax.set_xlim(limits[0])\n",
    "        ax.set_ylim(limits[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonalization of the Reconstructed Data <a name=\"orthogonalisation\"></a>\n",
    "(Transforming from the detector frame to the XU/CXI frame. See details below.)\n",
    "\n",
    "This part involves:\n",
    "- Retrieving the motor positions from the data file.\n",
    "- Building the reciprocal space grid.\n",
    "- Calculating the transformation matrices to map data from the detector frame to the lab (XU/CXI) frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = loader.load_motor_positions(scan, roi=roi)\n",
    "energy = loader.load_energy(scan)  # or define it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Reciprocal Space (Q-space) Grid Associated with the Detector Data\n",
    "\n",
    "To correctly compute the grid, the detector calibration parameters (`det_calib_params`) are required. In particular, the following parameters are mandatory:\n",
    "- Direct beam detector pixel position: `cch1` (vertical) and `cch2` (horizontal).\n",
    "- Pixel size: `pwidth1` and `pwidth2`.\n",
    "- Sample-to-detector distance: `distance`.\n",
    "\n",
    "Other parameters allow for more accurate computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_calib_params = loader.load_det_calib_params(scan)  # depends on the beamline\n",
    "\n",
    "# Fill the detetor calibration parameters manually\n",
    "# det_calib_params = {\n",
    "#     \"cch1\": , # direct beam position vertical,\n",
    "#     \"cch2\": , # horizontal\n",
    "#     \"pwidth1\": 5.5e-05,  # detector pixel size in m, eiger: 7.5e-5, maxipix: 5.5e-5\n",
    "#     \"pwidth2\": 5.5e-05,  # detector pixel size in m\n",
    "#     \"distance\":,  # sample to detector distance in m\n",
    "#     \"tiltazimuth\": .0,\n",
    "#     \"tilt\": .0,\n",
    "#     \"detrot\": .0,\n",
    "#     \"outerangle_offset\": .0\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the geometry associated to the beamline <a name=\"geometry\"></a>\n",
    "\n",
    "To check the geometry: ```print(geometry)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the appropriate geometry\n",
    "geometry = cdiutils.Geometry.from_setup(\"ID01\")\n",
    "\n",
    "# Initialise the space converter\n",
    "converter = cdiutils.SpaceConverter(\n",
    "    geometry,\n",
    "    det_calib_params,\n",
    "    energy=energy,\n",
    "    roi=roi[2:]\n",
    ")\n",
    "\n",
    "# The Q space area is initialised only for the selected roi used\n",
    "# before cropping the data\n",
    "converter.init_q_space(**angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Whether the Q-space Gridding Has Worked Properly\n",
    "\n",
    "To assess this, we'll need information about the Bragg reflection that was probed and the lattice parameter of the material.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What Bragg reflection did you measure?\n",
    "hkl = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: cropped_det_ref is the pixel reference chosen at the beginning. \n",
    "# It is the very centre of the cropped data.\n",
    "q_lab_ref = converter.index_det_to_q_lab(cropped_det_ref)\n",
    "dspacing_ref = converter.dspacing(q_lab_ref)\n",
    "lattice_parameter_ref = converter.lattice_parameter(q_lab_ref, hkl)\n",
    "print(\n",
    "    f\"The d-spacing and 'effective' lattice parameter are respectively \"\n",
    "    f\"{dspacing_ref:.4f} and {lattice_parameter_ref:.4f} angstroms.\\n\"\n",
    "    \"Is that what you expect?! -> If not, the detector calibration might \"\n",
    "    \"be wrong.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the interpolators in both reciprocal and direct spaces.\n",
    "Then we can orthogonalise in both spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.init_interpolator(space=\"both\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the orthogonalised intensity\n",
    "ortho_intensity = converter.orthogonalise_to_q_lab(cleaned_data)\n",
    "\n",
    "# This is the regular Q-space grid\n",
    "qx, qy, qz = converter.get_q_lab_regular_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the intensity in the orthogonal Q-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_spacing = [np.mean(np.diff(q)) for q in (qx, qy, qz)]\n",
    "q_centre = (qx.mean(), qy.mean(), qz.mean())\n",
    "\n",
    "figure, axes = cdiutils.plot.slice.plot_volume_slices(\n",
    "    ortho_intensity,\n",
    "    voxel_size=q_spacing,\n",
    "    data_centre=q_centre,\n",
    "    title=\"Orthogonalised intensity in the Q-lab frame\",\n",
    "    norm=LogNorm(),\n",
    "    convention=\"xu\",\n",
    "    show=False\n",
    ")\n",
    "cdiutils.plot.add_labels(axes, space=\"rcp\", convention=\"xu\")\n",
    "display(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonalisation in Direct Space\n",
    "The voxel size can be changed here (must be a float, tuple, list, or np.ndarray in nm). If not specified, the previously determined voxel size will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = converter.direct_lab_voxel_size\n",
    "voxel_size = 20  # or define it manually\n",
    "\n",
    "ortho_obj = converter.orthogonalise_to_direct_lab(mode, voxel_size)\n",
    "voxel_size = converter.direct_lab_voxel_size\n",
    "print(f\"The target voxel size is: {voxel_size} nm.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isosurface, _ = cdiutils.utils.find_isosurface(np.abs(ortho_obj), plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isosurface = 0.3  # Choose the isosurface value if not happy with the estimated one\n",
    "ortho_support = cdiutils.utils.make_support(np.abs(ortho_obj), isosurface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = {}\n",
    "axes = {}\n",
    "\n",
    "figures[\"amp\"], axes[\"amp\"] = cdiutils.plot.plot_volume_slices(\n",
    "    np.abs(ortho_obj),\n",
    "    support=ortho_support,\n",
    "    voxel_size=voxel_size,\n",
    "    data_centre=(0, 0, 0),\n",
    "    convention=\"xu\",\n",
    "    title=\"Amplitude\",\n",
    "    show=False\n",
    ")\n",
    "cdiutils.plot.add_labels(axes[\"amp\"], space=\"direct\", convention=\"xu\")\n",
    "\n",
    "figures[\"phase\"], axes[\"phase\"] = cdiutils.plot.plot_volume_slices(\n",
    "    np.angle(ortho_obj) * ortho_support,\n",
    "    support=ortho_support,\n",
    "    data_centre=(0, 0, 0),\n",
    "    voxel_size=voxel_size,\n",
    "    cmap=\"cet_CET_C9s_r\",\n",
    "    convention=\"xu\",\n",
    "    vmin=-np.pi,\n",
    "    vmax=np.pi,\n",
    "    title=\"Phase (rad)\",\n",
    "    show=False\n",
    ")\n",
    "cdiutils.plot.add_labels(axes[\"phase\"], space=\"direct\", convention=\"xu\")\n",
    "\n",
    "display(figures[\"amp\"], figures[\"phase\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convention Conversion <a name=\"convention\"></a>\n",
    "\n",
    "In the community, the CXI convention (https://cxidb.org/cxi.html) is often used. Therefore, *cdiutils* offers functions to transition from the *xrayutilities* convention (XU) to the CXI convention.\n",
    "\n",
    "* In the XU convention:\n",
    "    * Data are stored in the following way: $[\\text{axis}_{0} = x_{\\text{XU}}, \\text{axis}_{1} = y_{\\text{XU}}, \\text{axis}_{2} = z_{\\text{XU}}]$\n",
    "    * $x_{\\text{XU}}$: pointing away from the light source\n",
    "    * $y_{\\text{XU}}$: outboard\n",
    "    * $z_{\\text{XU}}$: vertical up\n",
    "\n",
    "* In the CXI convention:\n",
    "    * Data are stored in the following way: $[\\text{axis}_{0} = z_{\\text{CXI}}, \\text{axis}_{1} = y_{\\text{CXI}}, \\text{axis}_{2} = x_{\\text{CXI}}]$\n",
    "    * $x_{\\text{CXI}}$: horizontal, completing the right-handed system\n",
    "    * $y_{\\text{CXI}}$: vertical up\n",
    "    * $z_{\\text{CXI}}$: pointing away from the light source\n",
    "\n",
    "![XU_and_CXI](https://github.com/clatlan/cdiutils/assets/38456566/5db91309-0735-4910-9090-5299666f6994)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxi_ortho_obj = converter.xu_to_cxi(ortho_obj)\n",
    "cxi_ortho_support = converter.xu_to_cxi(ortho_support)\n",
    "cxi_voxel_size = converter.xu_to_cxi(voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Quantitative Structural Properties <a name=\"properties\"></a>\n",
    "\n",
    "Here we are going to use the `PostProcessor` class, which provides a variety of static methods, including:\n",
    "\n",
    "- `flip_reconstruction`: Needed if you determine that you have the complex conjugate solution.\n",
    "- `apodize`: Required to avoid high-frequency artifacts. It cuts the reciprocal space signal with a 3D window. This window can be \"blackman\", \"hamming\", \"hann\", \"blackmanharris\", \"gaussian\", and many others.\n",
    "- `unwrap_phase`: Unwraps the phase for the voxels contained within the given support. It uses the `skimage.restoration.unwrap_phase` function.\n",
    "- `remove_phase_ramp`: Removes the phase ramp of the object. It uses a linear regression model to find the ramp in 3D before removing it from the data.\n",
    "- `phase_offset_to_zero`: Sets the phase offset to zero, i.e., the average phase over all voxels within the support will be zero.\n",
    "- `get_displacement`: Computes the displacement using the phase and the position of the reciprocal space node considered as the center of the Bragg peak.\n",
    "- `get_het_normal_strain`: Extracts the strain defined as the *heterogeneous normal* strain along the direction of the reciprocal space node reference. Two methods are possible:\n",
    "    * The `numpy.gradient` traditional method. This method loses voxels at the surface.\n",
    "    * The hybrid gradient that provides a second-order derivative for the bulk voxels and a first-order derivative for surface voxels. This allows for accurate computation of the strain at the surface.\n",
    "\n",
    "Finally, there is a method that utilises all the others so you don't have to manage them individually: `get_structural_properties`. This method generates multiple quantities of interest, including:\n",
    "* Displacement maps\n",
    "* Strain maps\n",
    "* d-spacing maps\n",
    "* Lattice parameter maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, optionally flip and/or apodize the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cxi_ortho_obj = cdiutils.process.PostProcessor.flip_reconstruction(cxi_ortho_obj)\n",
    "cxi_ortho_obj = cdiutils.process.PostProcessor.apodize(cxi_ortho_obj, \"blackman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract the structural properties!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_props = cdiutils.process.PostProcessor.get_structural_properties(\n",
    "    cxi_ortho_obj,\n",
    "    isosurface=0.4,\n",
    "    g_vector=converter.xu_to_cxi(q_lab_ref),\n",
    "    hkl=hkl,\n",
    "    voxel_size=cxi_voxel_size,\n",
    "    handle_defects=False  # this is whether you expect a defect.\n",
    ")\n",
    "\n",
    "for prop, value in struct_props.items():\n",
    "    print(f\"{prop}: \", end=\"\")\n",
    "    if isinstance(value, (np.ndarray)) and value.ndim > 1:\n",
    "        print(f\"3D array of shape: {value.shape}\")\n",
    "    elif isinstance(value, (list, tuple)):\n",
    "        if isinstance(value[0], np.ndarray):\n",
    "            print(f\"tuple or list of length = {len(value)}\")\n",
    "        else:\n",
    "            print(value)\n",
    "    else:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancy summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = {\n",
    "    k: struct_props[k]\n",
    "    for k in [\n",
    "        \"amplitude\", \"phase\", \"displacement\", \"het_strain\", \"lattice_parameter\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "table_info = {\n",
    "    \"Isosurface\": isosurface,\n",
    "    \"Averaged Lat. Par. (Å)\":np.nanmean(struct_props[\"lattice_parameter\"]),\n",
    "    \"Averaged d-spacing (Å)\": np.nanmean(struct_props[\"dspacing\"])\n",
    "}\n",
    "\n",
    "summary_fig = cdiutils.pipeline.PipelinePlotter.summary_plot(\n",
    "    title=f\"Summary figure, Scan #{scan}\",\n",
    "    support=struct_props[\"support\"],\n",
    "    table_info=table_info,\n",
    "    voxel_size=cxi_voxel_size,\n",
    "    **to_plot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D view of the strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cdiutils.plot.volume.plot_3d_surface_projections(\n",
    "    data=struct_props[\"het_strain\"],\n",
    "    support=struct_props[\"support\"],\n",
    "    voxel_size=cxi_voxel_size,\n",
    "    cmap=\"cet_CET_D13\",\n",
    "    vmin=-np.nanmax(np.abs(struct_props[\"het_strain\"])),\n",
    "    vmax=np.nanmax(np.abs(struct_props[\"het_strain\"])),\n",
    "    cbar_title=r\"Strain (%)\",\n",
    "    title=f\"3D views of the strain, Scan #{scan}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path of the directory you want to save the data in\n",
    "dump_dir = f\"results/{sample_name}/S{scan}_step_by_step/\" \n",
    "\n",
    "if os.path.isdir(dump_dir):\n",
    "    print(\n",
    "        \"[INFO] Dump directory already exists, results will be saved in\\n\",\n",
    "        dump_dir\n",
    "    )\n",
    "else:\n",
    "    print(f\"[INFO] Creating the dump directory at: {dump_dir}\")\n",
    "    os.makedirs(dump_dir, exist_ok=True)\n",
    "\n",
    "to_save = {\n",
    "    \"isosurface\": isosurface,\n",
    "    \"q_lab_reference\": q_lab_ref,\n",
    "    \"dspacing_reference\": dspacing_ref,\n",
    "    \"lattice_parameter_reference\": lattice_parameter_ref\n",
    "}\n",
    "\n",
    "# Select the data you want to save\n",
    "to_save = {\n",
    "    \"isosurface\": isosurface,\n",
    "    \"q_lab_reference\": q_lab_ref,\n",
    "    \"dspacing_reference\": dspacing_ref,\n",
    "    \"lattice_parameter_reference\": lattice_parameter_ref\n",
    "}\n",
    "\n",
    "to_save.update(struct_props)\n",
    "\n",
    "# Save as .npz file\n",
    "np.savez(f\"{dump_dir}/S{scan}_structural_properties.npz\", **to_save)\n",
    "\n",
    "# Save as .vti file\n",
    "# This is for 3D visualisation, so we do not need to save everything.\n",
    "to_save_as_vti = {\n",
    "    k: struct_props[k]\n",
    "    for k in [\n",
    "        \"amplitude\", \"support\", \"phase\", \"displacement\", \"het_strain\",\n",
    "        \"het_strain_from_dspacing\", \"lattice_parameter\",\n",
    "        \"dspacing\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Also, we want to avoid nan values as they will mess up the visualisation.\n",
    "# Therefore, nan value are replaced by average value of the quantity.\n",
    "for k in (\n",
    "    \"het_strain\", \"het_strain_from_dspacing\", \"dspacing\"\n",
    "    \"lattice_parameter\", \"displacement\"\n",
    "):\n",
    "    to_save_as_vti[k] = np.where(\n",
    "        np.isnan(to_save_as_vti[k]),\n",
    "        np.nanmean(to_save_as_vti[k]),\n",
    "        to_save_as_vti[k]\n",
    "    )\n",
    "\n",
    "\n",
    "cdiutils.io.save_as_vti(\n",
    "    f\"{dump_dir}/S{scan}_structural_properties.vti\",\n",
    "    voxel_size=voxel_size,\n",
    "    cxi_convention=True,\n",
    "    **to_save_as_vti\n",
    ")\n",
    "\n",
    "print(\"\\n[INFO] data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further cells to come...\n",
    "\n",
    "Please send comments and suggestions or report any issues you've encountered to:\n",
    "[clement.atlan@esrf.fr](mailto:clement.atlan@esrf.fr?subject=cdiutils)\n",
    "\n",
    "Or raise issues on the dedicated [GitHub page](https://github.com/clatlan/cdiutils/issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To plot the data with cdiutils ```plot_volume_slices``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, plot_configs = cdiutils.plot.set_plot_configs()\n",
    "for prop in (\n",
    "        \"amplitude\", \"support\", \"phase\",\n",
    "        \"displacement\", \"het_strain\", \"dspacing\"\n",
    "):\n",
    "    figures[prop], axes[prop] = cdiutils.plot.slice.plot_volume_slices(\n",
    "        struct_props[prop]*cdiutils.utils.zero_to_nan(struct_props[\"support\"]),\n",
    "        support=struct_props[\"support\"],\n",
    "        voxel_size=cxi_voxel_size,\n",
    "        data_centre=(0, 0, 0),\n",
    "        vmin=plot_configs[prop][\"vmin\"],\n",
    "        vmax=plot_configs[prop][\"vmax\"],\n",
    "        cmap=plot_configs[prop][\"cmap\"],\n",
    "        title=prop,\n",
    "        show=False\n",
    "    )\n",
    "    cdiutils.plot.add_labels(axes[prop])\n",
    "    display(figures[prop])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "This notebook was created by Clément Atlan, ESRF, 2025. It is part of the `cdiutils` package, which provides tools for BCDI data analysis and visualisation.\n",
    "If you have used this notebook or the `cdiutils` package in your research, please consider citing the package https://github.com/clatlan/cdiutils/\n",
    "You'll find the citation information in the `cdiutils` package documentation.\n",
    "\n",
    "```bibtex\n",
    "@software{Atlan_Cdiutils_A_python,\n",
    "author = {Atlan, Clement},\n",
    "doi = {10.5281/zenodo.7656853},\n",
    "license = {MIT},\n",
    "title = {{Cdiutils: A python package for Bragg Coherent Diffraction Imaging processing, analysis and visualisation workflows}},\n",
    "url = {https://github.com/clatlan/cdiutils},\n",
    "version = {0.2.0}\n",
    "}\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
